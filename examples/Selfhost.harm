module Selfhost

-- This program is just a test to see how far I could get
-- if I decide to selfhost this language in the future.

import IO.Console as Console
import IO.File as File
import Data.Maybe as Maybe exposing (Just, Nothing)
import Data.String as String
import Data.Char as Char
import System.Environment as Environment

enum Token
    -- Literals
    = TkIdentifier (string)
    -- Keywords
    | TkModule
    | TkImport
    | TkAs
    | TkExposing
    | TkForeign
    | TkEnum
    | TkFun
    | TkCase
    | TkOf
    | TkEnd
    | TkIf
    | TkThen
    | TkElse
    | TkLet
    | TkIn
    -- Punctuation
    | TkOpenParen
    | TkCloseParen
    | TkDot
    | TkComma
    | TkArrow
    -- Operators
    | TkMinus
    -- Special
    | TkUnknown (string)
    | TkEOF

fun tokenize_identifier(s: string, i: int, identifier: string) -> Token =
    case String.get (s, i) of
        | Just (c) if Char.isAlphabetic $ c => tokenize_identifier (s, i + 1, identifier ++ c)
        | else => TkIdentifier (identifier)
    end

fun tokenize_(s: string, i: int, tokens: [Token]) -> Maybe<[Token]> =
    case String.length $ s of
        | 0 => Just (tokens ++ [TkEOF])
        | else => case String.get (s, i) of
            | Just (c) if Char.isWhitespace $ c => tokenize_ (s, i + 1, tokens)
            | Just (c) if Char.isAlphabetic $ c =>
                let token = tokenize_identifier (s, i, "") in
                case token of
                    | TkIdentifier (str) => let len = String.length $ str in 
                    case str of
                        | "module" => tokenize_ (s, i + len, tokens ++ [TkModule])
                        | "import" => tokenize_ (s, i + len, tokens ++ [TkImport])
                        | "as" => tokenize_ (s, i + len, tokens ++ [TkAs])
                        | "exposing" => tokenize_ (s, i + len, tokens ++ [TkExposing])
                        | else => tokenize_ (s, i + len, tokens ++ [token])
                    end
                    | else => tokenize_ (s, i + 1, tokens ++ [token])
                end
            | Just (c) => case c of
                | '(' => tokenize_ (s, i + 1, tokens ++ [TkOpenParen])
                | ')' => tokenize_ (s, i + 1, tokens ++ [TkCloseParen])
                | '.' => tokenize_ (s, i + 1, tokens ++ [TkDot])
                | ',' => tokenize_ (s, i + 1, tokens ++ [TkComma])
                | '-' => case String.get (s, i + 1) of
                    | Just (c) if c == '>' => tokenize_ (s, i + 2, tokens ++ [TkArrow])
                    | else => tokenize_ (s, i + 1, tokens ++ [TkMinus])
                end
                | else => tokenize_ (s, i + 1, tokens ++ [TkUnknown (c)])
            end
            | else => Just (tokens ++ [TkEOF])
        end
    end

fun tokenize(s: string) -> [Token] =
    case tokenize_ (s, 0, []) of
        | Just (tokens) => tokens
        | else => []
    end

enum AstNode
    = AstModule (string)
    | AstImport (string)
    | AstImportAs (string, string)
    | AstImportExposing (string, [string])
    | AstUnknown (Token)

fun parse(nodes: [AstNode], tokens: [Token], i: int) -> [AstNode] =
    case tokens[i] of
        | TkModule => case tokens[i + 1] of
            | TkIdentifier (name) => parse (nodes ++ [AstModule (name)], tokens, i + 2)
            | else => parse (nodes ++ [AstUnknown (tokens[i])], tokens, i + 1)
        end
        | TkImport => case tokens[i + 1] of
            | TkIdentifier (name) => case tokens[i + 2] of
                | TkAs => case tokens[i + 3] of
                    | TkIdentifier (alias) => parse (nodes ++ [AstImportAs (name, alias)], tokens, i + 4)
                    | else => parse (nodes ++ [AstUnknown (tokens[i])], tokens, i + 1)
                end
                | else => parse (nodes ++ [AstImport (name)], tokens, i + 2)
            end
            | else => parse (nodes ++ [AstUnknown (tokens[i])], tokens, i + 1)
        end
        | TkEOF => nodes
        | else => parse (nodes ++ [AstUnknown (tokens[i])], tokens, i + 1)
    end

fun main =
    let filename = Environment.args()[0] in
    let file = File.read $ filename in
    let tokens: [Token] = tokenize $ file in
    let ast = parse ([], tokens, 0) in
    Console.println $ ast